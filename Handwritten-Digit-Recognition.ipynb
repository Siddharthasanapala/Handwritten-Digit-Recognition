{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nhUD6v4wuxPD"
      },
      "outputs": [],
      "source": [
        "from keras import utils\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA6t3EOoyXY5",
        "outputId": "8633a98b-cabe-4aaa-ba15-198c819e946c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3HiRReOHzUYd"
      },
      "outputs": [],
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype( \"float32\" )\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype( \"float32\" )\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTB8ec5HzY_7",
        "outputId": "68c90094-06ef-4698-adb5-aba185482e7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 3s - 11ms/step - accuracy: 0.9214 - loss: 0.2794 - val_accuracy: 0.9627 - val_loss: 0.1344\n",
            "Epoch 2/10\n",
            "300/300 - 3s - 11ms/step - accuracy: 0.9686 - loss: 0.1104 - val_accuracy: 0.9724 - val_loss: 0.0937\n",
            "Epoch 3/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9800 - loss: 0.0703 - val_accuracy: 0.9745 - val_loss: 0.0784\n",
            "Epoch 4/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.9858 - loss: 0.0492 - val_accuracy: 0.9785 - val_loss: 0.0696\n",
            "Epoch 5/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.9901 - loss: 0.0359 - val_accuracy: 0.9799 - val_loss: 0.0653\n",
            "Epoch 6/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9930 - loss: 0.0261 - val_accuracy: 0.9796 - val_loss: 0.0610\n",
            "Epoch 7/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9948 - loss: 0.0199 - val_accuracy: 0.9793 - val_loss: 0.0647\n",
            "Epoch 8/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.9972 - loss: 0.0137 - val_accuracy: 0.9812 - val_loss: 0.0633\n",
            "Epoch 9/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9976 - loss: 0.0107 - val_accuracy: 0.9816 - val_loss: 0.0565\n",
            "Epoch 10/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9986 - loss: 0.0074 - val_accuracy: 0.9813 - val_loss: 0.0585\n",
            "Baseline Error: 1.87%\n"
          ]
        }
      ],
      "source": [
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal' , activation= \"relu\" ))\n",
        "  model.add(Dense(num_classes, kernel_initializer='normal' , activation= 'softmax' ))\n",
        "  # Compile model\n",
        "  model.compile(loss= \"categorical_crossentropy\" , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "  return model\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200,verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gsOpt4BX0SvW"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras import utils\n",
        "from keras import backend as K\n",
        "K.set_image_data_format( \"channels_first\" )\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "krK245541d55"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][channels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype( \"float32\" )\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype( \"float32\" )\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "# define a simple CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtiT_z9M2Ecn",
        "outputId": "a65f9d26-ff19-4e36-c70b-d73286805cbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.6291 - loss: 1.1627 - val_accuracy: 0.8215 - val_loss: 0.6058\n",
            "Epoch 2/10\n",
            "300/300 - 2s - 5ms/step - accuracy: 0.7938 - loss: 0.6488 - val_accuracy: 0.8753 - val_loss: 0.4375\n",
            "Epoch 3/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8275 - loss: 0.5437 - val_accuracy: 0.8899 - val_loss: 0.3753\n",
            "Epoch 4/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8457 - loss: 0.4874 - val_accuracy: 0.9010 - val_loss: 0.3404\n",
            "Epoch 5/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8578 - loss: 0.4502 - val_accuracy: 0.9073 - val_loss: 0.3078\n",
            "Epoch 6/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.8673 - loss: 0.4196 - val_accuracy: 0.9125 - val_loss: 0.2889\n",
            "Epoch 7/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8727 - loss: 0.3970 - val_accuracy: 0.9178 - val_loss: 0.2735\n",
            "Epoch 8/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8795 - loss: 0.3765 - val_accuracy: 0.9218 - val_loss: 0.2605\n",
            "Epoch 9/10\n",
            "300/300 - 1s - 2ms/step - accuracy: 0.8840 - loss: 0.3639 - val_accuracy: 0.9235 - val_loss: 0.2551\n",
            "Epoch 10/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.8882 - loss: 0.3501 - val_accuracy: 0.9277 - val_loss: 0.2403\n",
            "CNN Error: 7.23%\n"
          ]
        }
      ],
      "source": [
        "# define a simple CNN model\n",
        "def baseline_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, 5, 5, input_shape=(1, 28, 28), activation= \"relu\" ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation= 'relu' ))\n",
        "  model.add(Dense(num_classes, activation= 'softmax' ))\n",
        "  # Compile model\n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "  return model\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200,\n",
        "  verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iklisKQu2o1a"
      },
      "outputs": [],
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras import utils\n",
        "from keras import backend as K\n",
        "K.set_image_data_format( \"channels_first\" )\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-FRm3ceE3Ho0"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype( 'float32' )\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype( 'float32' )\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJVIxgO33l73",
        "outputId": "a0c3c332-bec7-49c9-90b6-2c45708675f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.8788 - loss: 0.3840 - val_accuracy: 0.9759 - val_loss: 0.0766\n",
            "Epoch 2/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9707 - loss: 0.0941 - val_accuracy: 0.9847 - val_loss: 0.0476\n",
            "Epoch 3/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9781 - loss: 0.0690 - val_accuracy: 0.9876 - val_loss: 0.0390\n",
            "Epoch 4/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9823 - loss: 0.0577 - val_accuracy: 0.9881 - val_loss: 0.0354\n",
            "Epoch 5/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9849 - loss: 0.0474 - val_accuracy: 0.9885 - val_loss: 0.0359\n",
            "Epoch 6/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9870 - loss: 0.0428 - val_accuracy: 0.9889 - val_loss: 0.0302\n",
            "Epoch 7/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9876 - loss: 0.0393 - val_accuracy: 0.9910 - val_loss: 0.0292\n",
            "Epoch 8/10\n",
            "300/300 - 1s - 4ms/step - accuracy: 0.9887 - loss: 0.0351 - val_accuracy: 0.9907 - val_loss: 0.0292\n",
            "Epoch 9/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9906 - loss: 0.0306 - val_accuracy: 0.9909 - val_loss: 0.0246\n",
            "Epoch 10/10\n",
            "300/300 - 1s - 3ms/step - accuracy: 0.9905 - loss: 0.0282 - val_accuracy: 0.9923 - val_loss: 0.0233\n",
            "Large CNN Error: 0.77%\n"
          ]
        }
      ],
      "source": [
        "# define the larger model\n",
        "\n",
        "def larger_model():\n",
        "\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation= 'relu' ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(15, (3, 3), activation= 'relu' ))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation= 'relu' ))\n",
        "  model.add(Dense(50, activation= 'relu' ))\n",
        "  model.add(Dense(num_classes, activation= 'softmax' ))\n",
        "  # Compile model\n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "  return model\n",
        "\n",
        "# build the model\n",
        "model = larger_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200,verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncshgu0s3qHd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "TensorFlow with GPU",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
