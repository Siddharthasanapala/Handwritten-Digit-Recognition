{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "eda304ae-b49a-4270-a03e-39dce793485e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "34781aac-6cab-4cb5-97c8-c3c7dc2ef7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.293390190000025\n",
            "GPU (s):\n",
            "0.10579952200004072\n",
            "GPU speedup over CPU: 78x\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import max_norm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "#K.set_image_dim_ordering(\"th\")\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "metadata": {
        "id": "tK-FiTcClaIU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype( \"float32\" )\n",
        "X_test = X_test.astype( \"float32\" )\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sq6sBr1mW7l",
        "outputId": "3564abf7-0c6a-495f-c411-d7364d4625f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3, 3), input_shape=(32, 32, 3), padding= \"same\" ,activation= \"relu\" , kernel_constraint=max_norm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32,(3, 3), activation= \"relu\" , padding= \"same\" ,kernel_constraint=max_norm(3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation= \"relu\" , kernel_constraint=max_norm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation= \"softmax\" ))"
      ],
      "metadata": {
        "id": "EdLZJkuQmz_D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "epochs = 25\n",
        "initial_learning_rate = 0.01\n",
        "decay_rate = 0.1\n",
        "decay_steps = epochs\n",
        "# Define a learning rate schedule using ExponentialDecay\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=decay_steps,\n",
        "    decay_rate=decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "# Initialize the SGD optimizer with the learning rate schedule\n",
        "sgd = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=False)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=categorical_crossentropy, optimizer=sgd, metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBDHlc7domdC",
        "outputId": "3ecc4738-2336-4dcf-8b65-ed5d563728ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               4194816   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4210090 (16.06 MB)\n",
            "Trainable params: 4210090 (16.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv6hl7nxprux",
        "outputId": "fc295252-0cc1-43e0-ff8f-907f98dcd5b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 - 13s - loss: 2.2300 - accuracy: 0.1655 - val_loss: 2.2413 - val_accuracy: 0.1878 - 13s/epoch - 8ms/step\n",
            "Epoch 2/25\n",
            "1563/1563 - 8s - loss: 2.2284 - accuracy: 0.1660 - val_loss: 2.2414 - val_accuracy: 0.1878 - 8s/epoch - 5ms/step\n",
            "Epoch 3/25\n",
            "1563/1563 - 8s - loss: 2.2287 - accuracy: 0.1663 - val_loss: 2.2416 - val_accuracy: 0.1879 - 8s/epoch - 5ms/step\n",
            "Epoch 4/25\n",
            "1563/1563 - 8s - loss: 2.2281 - accuracy: 0.1707 - val_loss: 2.2418 - val_accuracy: 0.1884 - 8s/epoch - 5ms/step\n",
            "Epoch 5/25\n",
            "1563/1563 - 8s - loss: 2.2292 - accuracy: 0.1679 - val_loss: 2.2420 - val_accuracy: 0.1887 - 8s/epoch - 5ms/step\n",
            "Epoch 6/25\n",
            "1563/1563 - 8s - loss: 2.2290 - accuracy: 0.1712 - val_loss: 2.2422 - val_accuracy: 0.1891 - 8s/epoch - 5ms/step\n",
            "Epoch 7/25\n",
            "1563/1563 - 9s - loss: 2.2296 - accuracy: 0.1674 - val_loss: 2.2424 - val_accuracy: 0.1889 - 9s/epoch - 6ms/step\n",
            "Epoch 8/25\n",
            "1563/1563 - 9s - loss: 2.2289 - accuracy: 0.1688 - val_loss: 2.2426 - val_accuracy: 0.1897 - 9s/epoch - 6ms/step\n",
            "Epoch 9/25\n",
            "1563/1563 - 8s - loss: 2.2294 - accuracy: 0.1697 - val_loss: 2.2428 - val_accuracy: 0.1897 - 8s/epoch - 5ms/step\n",
            "Epoch 10/25\n",
            "1563/1563 - 8s - loss: 2.2301 - accuracy: 0.1668 - val_loss: 2.2430 - val_accuracy: 0.1904 - 8s/epoch - 5ms/step\n",
            "Epoch 11/25\n",
            "1563/1563 - 9s - loss: 2.2303 - accuracy: 0.1700 - val_loss: 2.2432 - val_accuracy: 0.1908 - 9s/epoch - 6ms/step\n",
            "Epoch 12/25\n",
            "1563/1563 - 8s - loss: 2.2303 - accuracy: 0.1695 - val_loss: 2.2434 - val_accuracy: 0.1909 - 8s/epoch - 5ms/step\n",
            "Epoch 13/25\n",
            "1563/1563 - 8s - loss: 2.2308 - accuracy: 0.1698 - val_loss: 2.2436 - val_accuracy: 0.1912 - 8s/epoch - 5ms/step\n",
            "Epoch 14/25\n",
            "1563/1563 - 9s - loss: 2.2304 - accuracy: 0.1715 - val_loss: 2.2438 - val_accuracy: 0.1916 - 9s/epoch - 6ms/step\n",
            "Epoch 15/25\n",
            "1563/1563 - 9s - loss: 2.2305 - accuracy: 0.1708 - val_loss: 2.2440 - val_accuracy: 0.1919 - 9s/epoch - 6ms/step\n",
            "Epoch 16/25\n",
            "1563/1563 - 8s - loss: 2.2310 - accuracy: 0.1685 - val_loss: 2.2442 - val_accuracy: 0.1926 - 8s/epoch - 5ms/step\n",
            "Epoch 17/25\n",
            "1563/1563 - 9s - loss: 2.2309 - accuracy: 0.1694 - val_loss: 2.2444 - val_accuracy: 0.1923 - 9s/epoch - 6ms/step\n",
            "Epoch 18/25\n",
            "1563/1563 - 8s - loss: 2.2312 - accuracy: 0.1698 - val_loss: 2.2445 - val_accuracy: 0.1932 - 8s/epoch - 5ms/step\n",
            "Epoch 19/25\n",
            "1563/1563 - 8s - loss: 2.2312 - accuracy: 0.1696 - val_loss: 2.2447 - val_accuracy: 0.1937 - 8s/epoch - 5ms/step\n",
            "Epoch 20/25\n",
            "1563/1563 - 9s - loss: 2.2310 - accuracy: 0.1717 - val_loss: 2.2449 - val_accuracy: 0.1941 - 9s/epoch - 5ms/step\n",
            "Epoch 21/25\n",
            "1563/1563 - 8s - loss: 2.2316 - accuracy: 0.1731 - val_loss: 2.2451 - val_accuracy: 0.1940 - 8s/epoch - 5ms/step\n",
            "Epoch 22/25\n",
            "1563/1563 - 9s - loss: 2.2322 - accuracy: 0.1700 - val_loss: 2.2453 - val_accuracy: 0.1940 - 9s/epoch - 6ms/step\n",
            "Epoch 23/25\n",
            "1563/1563 - 8s - loss: 2.2321 - accuracy: 0.1717 - val_loss: 2.2455 - val_accuracy: 0.1941 - 8s/epoch - 5ms/step\n",
            "Epoch 24/25\n",
            "1563/1563 - 8s - loss: 2.2322 - accuracy: 0.1709 - val_loss: 2.2457 - val_accuracy: 0.1943 - 8s/epoch - 5ms/step\n",
            "Epoch 25/25\n",
            "1563/1563 - 8s - loss: 2.2327 - accuracy: 0.1710 - val_loss: 2.2459 - val_accuracy: 0.1947 - 8s/epoch - 5ms/step\n",
            "Accuracy: 19.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Large CNN model for the CIFAR-10 Dataset\n",
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Flatten ,MaxPooling2D ,Conv2D\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "#K.set_image_dim_ordering( \"th\" )"
      ],
      "metadata": {
        "id": "JXevvyeUtg8p"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# normalize inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype( \"float32\" )\n",
        "X_test = X_test.astype( \"float32\" )\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "metadata": {
        "id": "2ealjENqu4VY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation= \"relu\" ,padding= \"same\" ))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation= \"relu\" , padding= \"same\" ))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64,(3, 3), activation= \"relu\" , padding= \"same\" ))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation= \"relu\" , padding= \"same\" ))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation= \"relu\" , padding= \"same\" ))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation= \"relu\" , padding= \"same\" ))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation= \"relu\" , kernel_constraint=max_norm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation= \"relu\" , kernel_constraint=max_norm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation= \"softmax\" ))"
      ],
      "metadata": {
        "id": "a7XQNSNqu-Se"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.losses import categorical_crossentropy\n",
        "import tensorflow as tf\n",
        "\n",
        "# Compile model\n",
        "epochs = 25\n",
        "initial_learning_rate = 0.01\n",
        "\n",
        "decay_rate = 0.1\n",
        "\n",
        "# Define the learning rate schedule using ExponentialDecay\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=epochs,\n",
        "    decay_rate=decay_rate,\n",
        "    staircase=True)\n",
        "\n",
        "# Initialize the SGD optimizer with the learning rate schedule\n",
        "sgd = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=False)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=categorical_crossentropy, optimizer=sgd, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "u1ItaNb5x9Ye"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crtiGHIIy9WF",
        "outputId": "499720fb-81c8-4668-80f8-c317ee51e443"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 16, 16, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 8, 8, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 4, 4, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2915114 (11.12 MB)\n",
            "Trainable params: 2915114 (11.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs,batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7f7Ijk_y95S",
        "outputId": "f9b967d6-cfd1-4c71-9806-bf6e1f1079cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "782/782 [==============================] - 12s 12ms/step - loss: 2.2997 - accuracy: 0.1106 - val_loss: 2.3013 - val_accuracy: 0.0999\n",
            "Epoch 2/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2994 - accuracy: 0.1099 - val_loss: 2.3013 - val_accuracy: 0.0999\n",
            "Epoch 3/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2995 - accuracy: 0.1095 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 4/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1101 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 5/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2995 - accuracy: 0.1108 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 6/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2993 - accuracy: 0.1117 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 7/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2995 - accuracy: 0.1111 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 8/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2993 - accuracy: 0.1103 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 9/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1104 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 10/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1111 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 11/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2997 - accuracy: 0.1091 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 12/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2997 - accuracy: 0.1087 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 13/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2995 - accuracy: 0.1101 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 14/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2998 - accuracy: 0.1092 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 15/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1116 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 16/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1125 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 17/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2997 - accuracy: 0.1104 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 18/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2997 - accuracy: 0.1085 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 19/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2999 - accuracy: 0.1094 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 20/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1098 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 21/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1094 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 22/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1103 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 23/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2994 - accuracy: 0.1110 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 24/25\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.2997 - accuracy: 0.1126 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Epoch 25/25\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.2996 - accuracy: 0.1099 - val_loss: 2.3014 - val_accuracy: 0.0999\n",
            "Accuracy: 9.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize inputs\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.0005)  # Adjust learning rate if needed\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25, batch_size=64)\n",
        "\n",
        "# Evaluate model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1] * 100))\n"
      ],
      "metadata": {
        "id": "Eakm2PXJ28LR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}